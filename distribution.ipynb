{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "class distribution:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    @staticmethod\n",
    "    def analyze(X, Y, evaluation = 'mmd'):\n",
    "        if evaluation == 'mmd':\n",
    "            return distribution.mmd_rbf(X, Y) \n",
    "    \n",
    "    @staticmethod\n",
    "    def guassian_kernel(source, target, kernel_mul=2.0, kernel_num=5, fix_sigma=None):\n",
    "        '''\n",
    "        将源域数据和目标域数据转化为核矩阵\n",
    "        Params: \n",
    "         source: 源域数据，行表示样本数目，列表示样本数据维度\n",
    "         target: 目标域数据 同source\n",
    "         kernel_mul: 多核MMD，以bandwidth为中心，两边扩展的基数，比如bandwidth/kernel_mul, bandwidth, bandwidth*kernel_mul\n",
    "         kernel_num: 取不同高斯核的数量\n",
    "         fix_sigma: 是否固定，如果固定，则为单核MMD\n",
    "     Return:\n",
    "      sum(kernel_val): 多个核矩阵之和\n",
    "        '''\n",
    "        n_samples = int(source.size()[0])+int(target.size()[0])\n",
    "        # 求矩阵的行数，即两个域的的样本总数，一般source和target的尺度是一样的，这样便于计算\n",
    "        total = torch.cat([source, target], dim=0)#将source,target按列方向合并\n",
    "        \n",
    "        #将total复制（n+m）份\n",
    "        total0 = total.unsqueeze(0).expand(int(total.size(0)), int(total.size(0)), int(total.size(1)))\n",
    "        #将total的每一行都复制成（n+m）行，即每个数据都扩展成（n+m）份\n",
    "        total1 = total.unsqueeze(1).expand(int(total.size(0)), int(total.size(0)), int(total.size(1)))\n",
    "        # total1 - total2 得到的矩阵中坐标（i,j, :）代表total中第i行数据和第j行数据之间的差 \n",
    "        # sum函数，对第三维进行求和，即平方后再求和，获得高斯核指数部分的分子，是L2范数的平方\n",
    "        L2_distance_square = ((total0-total1)**2).sum(2) \n",
    "        #调整高斯核函数的sigma值\n",
    "        if fix_sigma:\n",
    "            bandwidth = fix_sigma\n",
    "        else:\n",
    "            bandwidth = torch.sum(L2_distance_square).item() / (n_samples**2-n_samples)\n",
    "        # 多核MMD\n",
    "        #以fix_sigma为中值，以kernel_mul为倍数取kernel_num个bandwidth值（比如fix_sigma为1时，得到[0.25,0.5,1,2,4]\n",
    "        bandwidth /= kernel_mul ** (kernel_num // 2)\n",
    "        bandwidth_list = [bandwidth * (kernel_mul**i) for i in range(kernel_num)]\n",
    "#         print(bandwidth_list)\n",
    "        #高斯核函数的数学表达式\n",
    "        kernel_val = [torch.exp(-L2_distance_square / bandwidth_temp) for bandwidth_temp in bandwidth_list]\n",
    "        #得到最终的核矩阵\n",
    "        return sum(kernel_val)#/len(kernel_val)\n",
    "    @staticmethod\n",
    "    def mmd_rbf(source, target, kernel_mul=2.0, kernel_num=5, fix_sigma=None):\n",
    "        '''\n",
    "        计算源域数据和目标域数据的MMD距离\n",
    "        Params: \n",
    "         source: 源域数据，行表示样本数目，列表示样本数据维度\n",
    "         target: 目标域数据 同source\n",
    "         kernel_mul: 多核MMD，以bandwidth为中心，两边扩展的基数，比如bandwidth/kernel_mul, bandwidth, bandwidth*kernel_mul\n",
    "         kernel_num: 取不同高斯核的数量\n",
    "         fix_sigma: 是否固定，如果固定，则为单核MMD\n",
    "     Return:\n",
    "      loss: MMD loss\n",
    "        '''\n",
    "        source = torch.from_numpy(np.array(source).reshape(np.array(source).shape[0], -1))\n",
    "        target = torch.from_numpy(np.array(target).reshape(np.array(target).shape[0], -1))\n",
    "        source_num = int(source.size()[0])#一般默认为源域和目标域的batchsize相同\n",
    "        target_num = int(target.size()[0])\n",
    "        kernels = distribution.guassian_kernel(source, target,\n",
    "            kernel_mul=kernel_mul, kernel_num=kernel_num, fix_sigma=fix_sigma)\n",
    "        \n",
    "        #根据式（3）将核矩阵分成4部分\n",
    "        XX = torch.mean(kernels[:source_num, :source_num])\n",
    "        YY = torch.mean(kernels[source_num:, source_num:])\n",
    "        XY = torch.mean(kernels[:source_num, source_num:])\n",
    "        YX = torch.mean(kernels[source_num:, :source_num])\n",
    "        \n",
    "        loss = XX + YY -XY - YX\n",
    "        return loss#因为一般都是n==m，所以L矩阵一般不加入计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "import torch\n",
    "torch.from_numpy(a).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.from_numpy(np.array([1,2,3]).reshape(np.array([1,2,3]).shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
